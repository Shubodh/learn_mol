{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubodh/learn_mol/blob/vgae%2Fdimenet%2Fgatconv_shub_0soutput_issue/dimenet_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "sYz0jNVwo0LU",
        "outputId": "d0eb9660-c389-4501-d942-cf7f7338a2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/zotko/xyz2graph.git\n",
            "  Cloning https://github.com/zotko/xyz2graph.git to /tmp/pip-req-build-gjty8nt4\n",
            "  Running command git clone -q https://github.com/zotko/xyz2graph.git /tmp/pip-req-build-gjty8nt4\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (5.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (2.8.8)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting rdkit\n",
            "  Downloading rdkit-2022.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.3 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xyz2graph==2.0.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly) (8.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 73.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: xyz2graph, torch-geometric\n",
            "  Building wheel for xyz2graph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xyz2graph: filename=xyz2graph-2.0.0-py3-none-any.whl size=6087 sha256=f7d6e48ae3df04f0dd9aa22a8cac3c2837a73a0984e597a3ae12bc44a901b804\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n2ylibcc/wheels/2c/4f/6c/35eec158016e29fa89f15263a8a04b4980e34fdaf615df91d8\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=f0dd6bbc4a75c8fbe8a2fa7a34c05d74b90dbf60dc877ac7e9f4056144c55ac9\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built xyz2graph torch-geometric\n",
            "Installing collected packages: psutil, xyz2graph, torch-geometric, rdkit\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 rdkit-2022.9.3 torch-geometric-2.2.0 xyz2graph-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install git+https://github.com/zotko/xyz2graph.git plotly networkx torch_geometric rdkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "!pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKGQAkYHqC20",
        "outputId": "59d2ffd9-86da-4a9e-ef72-882cb65087fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 8.5 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 56.8 MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse, torch-scatter, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0+pt113cu116 torch-scatter-2.1.0+pt113cu116 torch-sparse-0.6.16+pt113cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xyz2graph import MolGraph, to_networkx_graph, to_plotly_figure\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.utils.convert import from_networkx\n",
        "from torch_geometric.utils import negative_sampling\n",
        "import re\n",
        "from itertools import combinations\n",
        "from math import sqrt\n",
        "from torch_geometric.nn import DimeNet\n",
        "from rdkit import Chem\n",
        "import random\n",
        "from torch_geometric.data import Dataset, Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch import Tensor\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch_geometric.datasets import QM9\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import time\n",
        "from rdkit.Chem import Draw\n",
        "import pandas as pd\n",
        "from torch_scatter import scatter\n",
        "import torch_geometric.datasets as data"
      ],
      "metadata": {
        "id": "HQ75GB04qEB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "pjobtn6yqFOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimenet"
      ],
      "metadata": {
        "id": "V_TWu27ZqdQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "from math import pi as PI\n",
        "from math import sqrt\n",
        "from typing import Callable, Optional, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, Linear\n",
        "from torch_scatter import scatter\n",
        "from torch_sparse import SparseTensor\n",
        "\n",
        "from torch_geometric.data import Dataset, download_url\n",
        "from torch_geometric.data.makedirs import makedirs\n",
        "from torch_geometric.nn import radius_graph\n",
        "from torch_geometric.nn.inits import glorot_orthogonal\n",
        "from torch_geometric.nn.resolver import activation_resolver\n",
        "from torch_geometric.typing import OptTensor\n",
        "\n",
        "qm9_target_dict = {\n",
        "    0: 'mu',\n",
        "    1: 'alpha',\n",
        "    2: 'homo',\n",
        "    3: 'lumo',\n",
        "    5: 'r2',\n",
        "    6: 'zpve',\n",
        "    7: 'U0',\n",
        "    8: 'U',\n",
        "    9: 'H',\n",
        "    10: 'G',\n",
        "    11: 'Cv',\n",
        "}\n",
        "\n",
        "\n",
        "class Envelope(torch.nn.Module):\n",
        "    def __init__(self, exponent: int):\n",
        "        super().__init__()\n",
        "        self.p = exponent + 1\n",
        "        self.a = -(self.p + 1) * (self.p + 2) / 2\n",
        "        self.b = self.p * (self.p + 2)\n",
        "        self.c = -self.p * (self.p + 1) / 2\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        p, a, b, c = self.p, self.a, self.b, self.c\n",
        "        x_pow_p0 = x.pow(p - 1)\n",
        "        x_pow_p1 = x_pow_p0 * x\n",
        "        x_pow_p2 = x_pow_p1 * x\n",
        "        return (1. / x + a * x_pow_p0 + b * x_pow_p1 +\n",
        "                c * x_pow_p2) * (x < 1.0).to(x.dtype)\n",
        "\n",
        "\n",
        "class BesselBasisLayer(torch.nn.Module):\n",
        "    def __init__(self, num_radial: int, cutoff: float = 5.0,\n",
        "                 envelope_exponent: int = 5):\n",
        "        super().__init__()\n",
        "        self.cutoff = cutoff\n",
        "        self.envelope = Envelope(envelope_exponent)\n",
        "\n",
        "        self.freq = torch.nn.Parameter(torch.Tensor(num_radial))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        with torch.no_grad():\n",
        "            torch.arange(1, self.freq.numel() + 1, out=self.freq).mul_(PI)\n",
        "        self.freq.requires_grad_()\n",
        "\n",
        "    def forward(self, dist: Tensor) -> Tensor:\n",
        "        dist = (dist.unsqueeze(-1) / self.cutoff)\n",
        "        return self.envelope(dist) * (self.freq * dist).sin()\n",
        "\n",
        "\n",
        "class SphericalBasisLayer(torch.nn.Module):\n",
        "    def __init__(self, num_spherical: int, num_radial: int,\n",
        "                 cutoff: float = 5.0, envelope_exponent: int = 5):\n",
        "        super().__init__()\n",
        "        import sympy as sym\n",
        "\n",
        "        from torch_geometric.nn.models.dimenet_utils import (\n",
        "            bessel_basis,\n",
        "            real_sph_harm,\n",
        "        )\n",
        "\n",
        "        assert num_radial <= 64\n",
        "        self.num_spherical = num_spherical\n",
        "        self.num_radial = num_radial\n",
        "        self.cutoff = cutoff\n",
        "        self.envelope = Envelope(envelope_exponent)\n",
        "\n",
        "        bessel_forms = bessel_basis(num_spherical, num_radial)\n",
        "        sph_harm_forms = real_sph_harm(num_spherical)\n",
        "        self.sph_funcs = []\n",
        "        self.bessel_funcs = []\n",
        "\n",
        "        x, theta = sym.symbols('x theta')\n",
        "        modules = {'sin': torch.sin, 'cos': torch.cos}\n",
        "        for i in range(num_spherical):\n",
        "            if i == 0:\n",
        "                sph1 = sym.lambdify([theta], sph_harm_forms[i][0], modules)(0)\n",
        "                self.sph_funcs.append(lambda x: torch.zeros_like(x) + sph1)\n",
        "            else:\n",
        "                sph = sym.lambdify([theta], sph_harm_forms[i][0], modules)\n",
        "                self.sph_funcs.append(sph)\n",
        "            for j in range(num_radial):\n",
        "                bessel = sym.lambdify([x], bessel_forms[i][j], modules)\n",
        "                self.bessel_funcs.append(bessel)\n",
        "\n",
        "    def forward(self, dist: Tensor, angle: Tensor, idx_kj: Tensor) -> Tensor:\n",
        "        dist = dist / self.cutoff\n",
        "        rbf = torch.stack([f(dist) for f in self.bessel_funcs], dim=1)\n",
        "        rbf = self.envelope(dist).unsqueeze(-1) * rbf\n",
        "\n",
        "        cbf = torch.stack([f(angle) for f in self.sph_funcs], dim=1)\n",
        "\n",
        "        n, k = self.num_spherical, self.num_radial\n",
        "        out = (rbf[idx_kj].view(-1, n, k) * cbf.view(-1, n, 1)).view(-1, n * k)\n",
        "        return out\n",
        "\n",
        "\n",
        "class EmbeddingBlock(torch.nn.Module):\n",
        "    def __init__(self, num_radial: int, hidden_channels: int, act: Callable):\n",
        "        super().__init__()\n",
        "        self.act = act\n",
        "\n",
        "        self.emb = Embedding(95, hidden_channels)\n",
        "        self.lin_rbf = Linear(num_radial, hidden_channels)\n",
        "        self.lin = Linear(3 * hidden_channels, hidden_channels)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.emb.weight.data.uniform_(-sqrt(3), sqrt(3))\n",
        "        self.lin_rbf.reset_parameters()\n",
        "        self.lin.reset_parameters()\n",
        "\n",
        "    def forward(self, x: Tensor, rbf: Tensor, i: Tensor, j: Tensor) -> Tensor:\n",
        "        x = self.emb(x)\n",
        "        rbf = self.act(self.lin_rbf(rbf))\n",
        "        return self.act(self.lin(torch.cat([x[i], x[j], rbf], dim=-1)))\n",
        "\n",
        "\n",
        "class ResidualLayer(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels: int, act: Callable):\n",
        "        super().__init__()\n",
        "        self.act = act\n",
        "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        glorot_orthogonal(self.lin1.weight, scale=2.0)\n",
        "        self.lin1.bias.data.fill_(0)\n",
        "        glorot_orthogonal(self.lin2.weight, scale=2.0)\n",
        "        self.lin2.bias.data.fill_(0)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return x + self.act(self.lin2(self.act(self.lin1(x))))\n",
        "\n",
        "\n",
        "class InteractionBlock(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels: int, num_bilinear: int,\n",
        "                 num_spherical: int, num_radial: int, num_before_skip: int,\n",
        "                 num_after_skip: int, act: Callable):\n",
        "        super().__init__()\n",
        "        self.act = act\n",
        "\n",
        "        self.lin_rbf = Linear(num_radial, hidden_channels, bias=False)\n",
        "        self.lin_sbf = Linear(num_spherical * num_radial, num_bilinear,\n",
        "                              bias=False)\n",
        "\n",
        "        # Dense transformations of input messages.\n",
        "        self.lin_kj = Linear(hidden_channels, hidden_channels)\n",
        "        self.lin_ji = Linear(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.W = torch.nn.Parameter(\n",
        "            torch.Tensor(hidden_channels, num_bilinear, hidden_channels))\n",
        "\n",
        "        self.layers_before_skip = torch.nn.ModuleList([\n",
        "            ResidualLayer(hidden_channels, act) for _ in range(num_before_skip)\n",
        "        ])\n",
        "        self.lin = Linear(hidden_channels, hidden_channels)\n",
        "        self.layers_after_skip = torch.nn.ModuleList([\n",
        "            ResidualLayer(hidden_channels, act) for _ in range(num_after_skip)\n",
        "        ])\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        glorot_orthogonal(self.lin_rbf.weight, scale=2.0)\n",
        "        glorot_orthogonal(self.lin_sbf.weight, scale=2.0)\n",
        "        glorot_orthogonal(self.lin_kj.weight, scale=2.0)\n",
        "        self.lin_kj.bias.data.fill_(0)\n",
        "        glorot_orthogonal(self.lin_ji.weight, scale=2.0)\n",
        "        self.lin_ji.bias.data.fill_(0)\n",
        "        self.W.data.normal_(mean=0, std=2 / self.W.size(0))\n",
        "        for res_layer in self.layers_before_skip:\n",
        "            res_layer.reset_parameters()\n",
        "        glorot_orthogonal(self.lin.weight, scale=2.0)\n",
        "        self.lin.bias.data.fill_(0)\n",
        "        for res_layer in self.layers_after_skip:\n",
        "            res_layer.reset_parameters()\n",
        "\n",
        "    def forward(self, x: Tensor, rbf: Tensor, sbf: Tensor, idx_kj: Tensor,\n",
        "                idx_ji: Tensor) -> Tensor:\n",
        "        rbf = self.lin_rbf(rbf)\n",
        "        sbf = self.lin_sbf(sbf)\n",
        "\n",
        "        x_ji = self.act(self.lin_ji(x))\n",
        "        x_kj = self.act(self.lin_kj(x))\n",
        "        x_kj = x_kj * rbf\n",
        "        x_kj = torch.einsum('wj,wl,ijl->wi', sbf, x_kj[idx_kj], self.W)\n",
        "        x_kj = scatter(x_kj, idx_ji, dim=0, dim_size=x.size(0))\n",
        "\n",
        "        h = x_ji + x_kj\n",
        "        for layer in self.layers_before_skip:\n",
        "            h = layer(h)\n",
        "        h = self.act(self.lin(h)) + x\n",
        "        for layer in self.layers_after_skip:\n",
        "            h = layer(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "\n",
        "\n",
        "class OutputBlock(torch.nn.Module):\n",
        "    def __init__(self, num_radial: int, hidden_channels: int,\n",
        "                 out_channels: int, num_layers: int, act: Callable):\n",
        "        super().__init__()\n",
        "        self.act = act\n",
        "\n",
        "        self.lin_rbf = Linear(num_radial, hidden_channels, bias=False)\n",
        "        self.lins = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.lins.append(Linear(hidden_channels, hidden_channels))\n",
        "        self.lin = Linear(hidden_channels, out_channels, bias=False)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        glorot_orthogonal(self.lin_rbf.weight, scale=2.0)\n",
        "        for lin in self.lins:\n",
        "            glorot_orthogonal(lin.weight, scale=2.0)\n",
        "            lin.bias.data.fill_(0)\n",
        "        self.lin.weight.data.fill_(0)\n",
        "\n",
        "    def forward(self, x: Tensor, rbf: Tensor, i: Tensor,\n",
        "                num_nodes: Optional[int] = None, debug=False) -> Tensor:\n",
        "        if debug:\n",
        "            print('inside output block')\n",
        "        x = self.lin_rbf(rbf) * x\n",
        "        if debug: print('after lin_rbf', x)\n",
        "        x = scatter(x, i, dim=0, dim_size=num_nodes)\n",
        "        for lin in self.lins:\n",
        "            x = self.act(lin(x))\n",
        "        if debug: print('after lins', x)\n",
        "        x = self.lin(x)\n",
        "        if debug: print('final output', x)\n",
        "        return x\n",
        "\n",
        "class DimeNet(torch.nn.Module):\n",
        "    r\"\"\"The directional message passing neural network (DimeNet) from the\n",
        "    `\"Directional Message Passing for Molecular Graphs\"\n",
        "    <https://arxiv.org/abs/2003.03123>`_ paper.\n",
        "    DimeNet transforms messages based on the angle between them in a\n",
        "    rotation-equivariant fashion.\n",
        "\n",
        "    .. note::\n",
        "\n",
        "        For an example of using a pretrained DimeNet variant, see\n",
        "        `examples/qm9_pretrained_dimenet.py\n",
        "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
        "        qm9_pretrained_dimenet.py>`_.\n",
        "\n",
        "    Args:\n",
        "        hidden_channels (int): Hidden embedding size.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        num_blocks (int): Number of building blocks.\n",
        "        num_bilinear (int): Size of the bilinear layer tensor.\n",
        "        num_spherical (int): Number of spherical harmonics.\n",
        "        num_radial (int): Number of radial basis functions.\n",
        "        cutoff (float, optional): Cutoff distance for interatomic\n",
        "            interactions. (default: :obj:`5.0`)\n",
        "        max_num_neighbors (int, optional): The maximum number of neighbors to\n",
        "            collect for each node within the :attr:`cutoff` distance.\n",
        "            (default: :obj:`32`)\n",
        "        envelope_exponent (int, optional): Shape of the smooth cutoff.\n",
        "            (default: :obj:`5`)\n",
        "        num_before_skip (int, optional): Number of residual layers in the\n",
        "            interaction blocks before the skip connection. (default: :obj:`1`)\n",
        "        num_after_skip (int, optional): Number of residual layers in the\n",
        "            interaction blocks after the skip connection. (default: :obj:`2`)\n",
        "        num_output_layers (int, optional): Number of linear layers for the\n",
        "            output blocks. (default: :obj:`3`)\n",
        "        act (str or Callable, optional): The activation function.\n",
        "            (default: :obj:`\"swish\"`)\n",
        "    \"\"\"\n",
        "\n",
        "    url = ('https://github.com/klicperajo/dimenet/raw/master/pretrained/'\n",
        "           'dimenet')\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_channels: int,\n",
        "        out_channels: int,\n",
        "        num_blocks: int,\n",
        "        num_bilinear: int,\n",
        "        num_spherical: int,\n",
        "        num_radial,\n",
        "        cutoff: float = 5.0,\n",
        "        max_num_neighbors: int = 32,\n",
        "        envelope_exponent: int = 5,\n",
        "        num_before_skip: int = 1,\n",
        "        num_after_skip: int = 2,\n",
        "        num_output_layers: int = 3,\n",
        "        act: Union[str, Callable] = 'swish',\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if num_spherical < 2:\n",
        "            raise ValueError(\"num_spherical should be greater than 1\")\n",
        "\n",
        "        act = activation_resolver(act)\n",
        "\n",
        "        self.cutoff = cutoff\n",
        "        self.max_num_neighbors = max_num_neighbors\n",
        "        self.num_blocks = num_blocks\n",
        "\n",
        "        self.rbf = BesselBasisLayer(num_radial, cutoff, envelope_exponent)\n",
        "        self.sbf = SphericalBasisLayer(num_spherical, num_radial, cutoff,\n",
        "                                       envelope_exponent)\n",
        "\n",
        "        self.emb = EmbeddingBlock(num_radial, hidden_channels, act)\n",
        "\n",
        "        self.output_blocks = torch.nn.ModuleList([\n",
        "            OutputBlock(num_radial, hidden_channels, out_channels,\n",
        "                        num_output_layers, act) for _ in range(num_blocks + 1)\n",
        "        ])\n",
        "\n",
        "        self.interaction_blocks = torch.nn.ModuleList([\n",
        "            InteractionBlock(hidden_channels, num_bilinear, num_spherical,\n",
        "                             num_radial, num_before_skip, num_after_skip, act)\n",
        "            for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        # self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.rbf.reset_parameters()\n",
        "        self.emb.reset_parameters()\n",
        "        for out in self.output_blocks:\n",
        "            out.reset_parameters()\n",
        "        for interaction in self.interaction_blocks:\n",
        "            interaction.reset_parameters()\n",
        "\n",
        "\n",
        "    def triplets(\n",
        "        self,\n",
        "        edge_index: Tensor,\n",
        "        num_nodes: int,\n",
        "    ) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
        "        row, col = edge_index  # j->i\n",
        "\n",
        "        value = torch.arange(row.size(0), device=row.device)\n",
        "        adj_t = SparseTensor(row=col, col=row, value=value,\n",
        "                             sparse_sizes=(num_nodes, num_nodes))\n",
        "        adj_t_row = adj_t[row]\n",
        "        num_triplets = adj_t_row.set_value(None).sum(dim=1).to(torch.long)\n",
        "\n",
        "        # Node indices (k->j->i) for triplets.\n",
        "        idx_i = col.repeat_interleave(num_triplets)\n",
        "        idx_j = row.repeat_interleave(num_triplets)\n",
        "        idx_k = adj_t_row.storage.col()\n",
        "        mask = idx_i != idx_k  # Remove i == k triplets.\n",
        "        idx_i, idx_j, idx_k = idx_i[mask], idx_j[mask], idx_k[mask]\n",
        "\n",
        "        # Edge indices (k-j, j->i) for triplets.\n",
        "        idx_kj = adj_t_row.storage.value()[mask]\n",
        "        idx_ji = adj_t_row.storage.row()[mask]\n",
        "\n",
        "        return col, row, idx_i, idx_j, idx_k, idx_kj, idx_ji\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        z: Tensor,\n",
        "        pos: Tensor,\n",
        "        batch: OptTensor = None,\n",
        "        debug = False\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\"\"\"\n",
        "        edge_index = radius_graph(pos, r=self.cutoff, batch=batch,\n",
        "                                  max_num_neighbors=self.max_num_neighbors)\n",
        "        if debug: print(edge_index)\n",
        "        i, j, idx_i, idx_j, idx_k, idx_kj, idx_ji = self.triplets(\n",
        "            edge_index, num_nodes=z.size(0))\n",
        "\n",
        "        # Calculate distances.\n",
        "        dist = (pos[i] - pos[j]).pow(2).sum(dim=-1).sqrt()\n",
        "\n",
        "        # Calculate angles.\n",
        "        pos_i = pos[idx_i]\n",
        "        pos_ji, pos_ki = pos[idx_j] - pos_i, pos[idx_k] - pos_i\n",
        "        a = (pos_ji * pos_ki).sum(dim=-1)\n",
        "        b = torch.cross(pos_ji, pos_ki).norm(dim=-1)\n",
        "        angle = torch.atan2(b, a)\n",
        "\n",
        "        rbf = self.rbf(dist)\n",
        "        sbf = self.sbf(dist, angle, idx_kj)\n",
        "        if debug: \n",
        "            print(\"RBF: \\n\", rbf)\n",
        "            print(\"SBF: \\n\", sbf)\n",
        "        # Embedding block.\n",
        "        x = self.emb(z, rbf, i, j)\n",
        "        P = self.output_blocks[0](x, rbf, i, num_nodes=pos.size(0), debug=debug)\n",
        "        if debug:\n",
        "            print(\"output after embedding layer\")\n",
        "            print(P)\n",
        "        # Interaction blocks.\n",
        "        for interaction_block, output_block in zip(self.interaction_blocks,\n",
        "                                                   self.output_blocks[1:]):\n",
        "            x = interaction_block(x, rbf, sbf, idx_kj, idx_ji)\n",
        "            P = P + output_block(x, rbf, i, debug=debug)\n",
        "            if debug:\n",
        "                print(\"output after interaction layer\")\n",
        "                print(P)\n",
        "                print(\"state after interaction layer\")\n",
        "                print(x)\n",
        "        # return P.sum(dim=0) if batch is None else scatter(P, batch, dim=0)\n",
        "        return P\n",
        "\n",
        "class DimeNet_OG(torch.nn.Module):\n",
        "    r\"\"\"The directional message passing neural network (DimeNet) from the\n",
        "    `\"Directional Message Passing for Molecular Graphs\"\n",
        "    <https://arxiv.org/abs/2003.03123>`_ paper.\n",
        "    DimeNet transforms messages based on the angle between them in a\n",
        "    rotation-equivariant fashion.\n",
        "\n",
        "    .. note::\n",
        "\n",
        "        For an example of using a pretrained DimeNet variant, see\n",
        "        `examples/qm9_pretrained_dimenet.py\n",
        "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
        "        qm9_pretrained_dimenet.py>`_.\n",
        "\n",
        "    Args:\n",
        "        hidden_channels (int): Hidden embedding size.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        num_blocks (int): Number of building blocks.\n",
        "        num_bilinear (int): Size of the bilinear layer tensor.\n",
        "        num_spherical (int): Number of spherical harmonics.\n",
        "        num_radial (int): Number of radial basis functions.\n",
        "        cutoff (float, optional): Cutoff distance for interatomic\n",
        "            interactions. (default: :obj:`5.0`)\n",
        "        max_num_neighbors (int, optional): The maximum number of neighbors to\n",
        "            collect for each node within the :attr:`cutoff` distance.\n",
        "            (default: :obj:`32`)\n",
        "        envelope_exponent (int, optional): Shape of the smooth cutoff.\n",
        "            (default: :obj:`5`)\n",
        "        num_before_skip (int, optional): Number of residual layers in the\n",
        "            interaction blocks before the skip connection. (default: :obj:`1`)\n",
        "        num_after_skip (int, optional): Number of residual layers in the\n",
        "            interaction blocks after the skip connection. (default: :obj:`2`)\n",
        "        num_output_layers (int, optional): Number of linear layers for the\n",
        "            output blocks. (default: :obj:`3`)\n",
        "        act (str or Callable, optional): The activation function.\n",
        "            (default: :obj:`\"swish\"`)\n",
        "    \"\"\"\n",
        "\n",
        "    url = ('https://github.com/klicperajo/dimenet/raw/master/pretrained/'\n",
        "           'dimenet')\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_channels: int,\n",
        "        out_channels: int,\n",
        "        num_blocks: int,\n",
        "        num_bilinear: int,\n",
        "        num_spherical: int,\n",
        "        num_radial,\n",
        "        cutoff: float = 5.0,\n",
        "        max_num_neighbors: int = 32,\n",
        "        envelope_exponent: int = 5,\n",
        "        num_before_skip: int = 1,\n",
        "        num_after_skip: int = 2,\n",
        "        num_output_layers: int = 3,\n",
        "        act: Union[str, Callable] = 'swish',\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if num_spherical < 2:\n",
        "            raise ValueError(\"num_spherical should be greater than 1\")\n",
        "\n",
        "        act = activation_resolver(act)\n",
        "\n",
        "        self.cutoff = cutoff\n",
        "        self.max_num_neighbors = max_num_neighbors\n",
        "        self.num_blocks = num_blocks\n",
        "\n",
        "        self.rbf = BesselBasisLayer(num_radial, cutoff, envelope_exponent)\n",
        "        self.sbf = SphericalBasisLayer(num_spherical, num_radial, cutoff,\n",
        "                                       envelope_exponent)\n",
        "\n",
        "        self.emb = EmbeddingBlock(num_radial, hidden_channels, act)\n",
        "\n",
        "        self.output_blocks = torch.nn.ModuleList([\n",
        "            OutputBlock(num_radial, hidden_channels, out_channels,\n",
        "                        num_output_layers, act) for _ in range(num_blocks + 1)\n",
        "        ])\n",
        "\n",
        "        self.interaction_blocks = torch.nn.ModuleList([\n",
        "            InteractionBlock(hidden_channels, num_bilinear, num_spherical,\n",
        "                             num_radial, num_before_skip, num_after_skip, act)\n",
        "            for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.rbf.reset_parameters()\n",
        "        self.emb.reset_parameters()\n",
        "        for out in self.output_blocks:\n",
        "            out.reset_parameters()\n",
        "        for interaction in self.interaction_blocks:\n",
        "            interaction.reset_parameters()\n",
        "\n",
        "\n",
        "    def triplets(\n",
        "        self,\n",
        "        edge_index: Tensor,\n",
        "        num_nodes: int,\n",
        "    ) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
        "        row, col = edge_index  # j->i\n",
        "\n",
        "        value = torch.arange(row.size(0), device=row.device)\n",
        "        adj_t = SparseTensor(row=col, col=row, value=value,\n",
        "                             sparse_sizes=(num_nodes, num_nodes))\n",
        "        adj_t_row = adj_t[row]\n",
        "        num_triplets = adj_t_row.set_value(None).sum(dim=1).to(torch.long)\n",
        "\n",
        "        # Node indices (k->j->i) for triplets.\n",
        "        idx_i = col.repeat_interleave(num_triplets)\n",
        "        idx_j = row.repeat_interleave(num_triplets)\n",
        "        idx_k = adj_t_row.storage.col()\n",
        "        mask = idx_i != idx_k  # Remove i == k triplets.\n",
        "        idx_i, idx_j, idx_k = idx_i[mask], idx_j[mask], idx_k[mask]\n",
        "\n",
        "        # Edge indices (k-j, j->i) for triplets.\n",
        "        idx_kj = adj_t_row.storage.value()[mask]\n",
        "        idx_ji = adj_t_row.storage.row()[mask]\n",
        "\n",
        "        return col, row, idx_i, idx_j, idx_k, idx_kj, idx_ji\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        z: Tensor,\n",
        "        pos: Tensor,\n",
        "        batch: OptTensor = None,\n",
        "        debug= False\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\"\"\"\n",
        "        edge_index = radius_graph(pos, r=self.cutoff, batch=batch,\n",
        "                                  max_num_neighbors=self.max_num_neighbors)\n",
        "\n",
        "        i, j, idx_i, idx_j, idx_k, idx_kj, idx_ji = self.triplets(\n",
        "            edge_index, num_nodes=z.size(0))\n",
        "\n",
        "        # Calculate distances.\n",
        "        dist = (pos[i] - pos[j]).pow(2).sum(dim=-1).sqrt()\n",
        "\n",
        "        # Calculate angles.\n",
        "        pos_i = pos[idx_i]\n",
        "        pos_ji, pos_ki = pos[idx_j] - pos_i, pos[idx_k] - pos_i\n",
        "        a = (pos_ji * pos_ki).sum(dim=-1)\n",
        "        b = torch.cross(pos_ji, pos_ki).norm(dim=-1)\n",
        "        angle = torch.atan2(b, a)\n",
        "\n",
        "        rbf = self.rbf(dist)\n",
        "        sbf = self.sbf(dist, angle, idx_kj)\n",
        "\n",
        "        # Embedding block.\n",
        "        x = self.emb(z, rbf, i, j)\n",
        "        P = self.output_blocks[0](x, rbf, i, num_nodes=pos.size(0), debug=debug)\n",
        "        if debug:  \n",
        "            print(\"output after embedding layer\")\n",
        "            print(P)\n",
        "        # Interaction blocks.\n",
        "        for interaction_block, output_block in zip(self.interaction_blocks,\n",
        "                                                   self.output_blocks[1:]):\n",
        "            x = interaction_block(x, rbf, sbf, idx_kj, idx_ji)\n",
        "            P = P + output_block(x, rbf, i, debug=debug)\n",
        "            if debug:\n",
        "                print(\"output after interaction layer\")\n",
        "                print(P)\n",
        "                print(\"state after interaction layer\")\n",
        "                print(x)\n",
        "        P = P.sum(dim=0) if batch is None else scatter(P, batch, dim=0)\n",
        "        return P\n",
        "        # return P.sum(dim=0) if batch is None else scatter(P, batch, dim=0)\n"
      ],
      "metadata": {
        "id": "5J1uxHuuqeQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimenet as a layer"
      ],
      "metadata": {
        "id": "jnVwMg3TrV03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DimeNetBasic(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim=1, heads=1,num_layers=1):\n",
        "        super(DimeNetBasic, self).__init__()\n",
        "        self.conv1 = []\n",
        "        self.conv1.append(DimeNet(\n",
        "            hidden_channels=64,\n",
        "            out_channels=hidden_channels,\n",
        "            num_blocks=4,\n",
        "            num_bilinear=8,\n",
        "            num_spherical=7,\n",
        "            num_radial=6,\n",
        "            cutoff=5.0,\n",
        "            envelope_exponent=5,\n",
        "            num_before_skip=1,\n",
        "            num_after_skip=2,\n",
        "            num_output_layers=3,\n",
        "        ))\n",
        "        self.conv1 = torch.nn.ModuleList(self.conv1)\n",
        "        # self.conv_mu = GATConv(hidden_channels, out_channels)\n",
        "        # self.conv_logstd = GATConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, pos, edge_index, batch, debug=False):\n",
        "        # print('Input:', x.shape)\n",
        "        for conv in self.conv1:\n",
        "            x = conv(x, pos, batch, debug).relu()\n",
        "        if debug: print('Post dimenet:', x)\n",
        "        x = x.sum(dim=0) if batch is None else scatter(x, batch, dim=0)\n",
        "        if debug: print('Post summation:', x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dQD3JrrArUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters and the model"
      ],
      "metadata": {
        "id": "3GG6FDl9zV_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_list_raw = data.QM9('./data/QM9')\n",
        "N = 100\n",
        "data_list = [g for g in data_list_raw[:N] if g.x.shape[0] < 20]\n",
        "# Define the device (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model and datasets to the device\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "num_layers = 1\n",
        "out_channels = 2\n",
        "num_features = data_list[0].x.shape[1]\n",
        "epochs = 20\n",
        "edge_dim = data_list[0].edge_attr.shape[1]\n",
        "heads = 1\n",
        "hidden_channels = 1\n",
        "print(f'Node features: {num_features}')\n",
        "print(f'Edge features: {edge_dim}')\n",
        "split = [0.8, 0.2]\n",
        "N_train = int(N * split[0])\n",
        "train_data = data_list[:N_train]\n",
        "test_data = data_list[N_train:]\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Qp3eGotZXD",
        "outputId": "7b50abed-f47b-43ea-f2e3-6396b208ac70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features: 11\n",
            "Edge features: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "    \"in_channels\": num_features,\n",
        "    \"hidden_channels\": hidden_channels,\n",
        "    \"out_channels\": out_channels,\n",
        "    \"num_layers\": num_layers,\n",
        "    \"edge_dim\": edge_dim,\n",
        "    \"heads\": heads\n",
        "    }\n",
        "# model\n",
        "model = DimeNetBasic(**model_config).to(device)\n",
        "model_og = DimeNet_OG(\n",
        "            hidden_channels=64,\n",
        "            out_channels=hidden_channels,\n",
        "            num_blocks=4,\n",
        "            num_bilinear=8,\n",
        "            num_spherical=7,\n",
        "            num_radial=6,\n",
        "            cutoff=5.0,\n",
        "            envelope_exponent=5,\n",
        "            num_before_skip=1,\n",
        "            num_after_skip=2,\n",
        "            num_output_layers=3,\n",
        "        ).to(device)"
      ],
      "metadata": {
        "id": "3WQ7ESbrmP2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "o2Rc5MxozRgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('before training')\n",
        "z = []\n",
        "for g in train_loader:\n",
        "    g = g.to(device)\n",
        "    z.append(model(g.z, g.pos, g.edge_index, g.batch).detach().cpu().numpy())\n",
        "z = np.vstack(z)\n",
        "print(z.shape)\n",
        "cnt = 0\n",
        "for idx in range(z.shape[0]):\n",
        "    if np.any(z[idx] != 0): cnt+=1\n",
        "print(f'number of non-zero embeddings: {cnt}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ro9ahFKwCsx",
        "outputId": "a79d029a-8e4d-4be7-9e28-beea0fc6dfbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training\n",
            "tensor([[  1,   2,   3,  ..., 226, 227, 228],\n",
            "        [  0,   0,   0,  ..., 229, 229, 229]], device='cuda:0')\n",
            "Post_dimenet: torch.Size([230, 1])\n",
            "tensor([[  1,   2,   3,  ..., 327, 329, 330],\n",
            "        [  0,   0,   0,  ..., 331, 331, 331]], device='cuda:0')\n",
            "Post_dimenet: torch.Size([332, 1])\n",
            "tensor([[  1,   2,   3,  ..., 189, 190, 191],\n",
            "        [  0,   0,   0,  ..., 192, 192, 192]], device='cuda:0')\n",
            "Post_dimenet: torch.Size([193, 1])\n",
            "(80, 1)\n",
            "number of non-zero embeddings: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "train_loss = []\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    # Loop over the training dataset\n",
        "    for graph in train_loader:\n",
        "        # Extract the data and labels\n",
        "        graph = graph.to(device)\n",
        "        x, pos, edge_index, y, batch = graph.z, graph.pos, graph.edge_index, graph.y[:, 0], graph.batch\n",
        "\n",
        "        # Reset the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(x, pos, edge_index, batch)\n",
        "        loss = loss_fn(output, y)\n",
        "        train_loss.append(loss.item())\n",
        "        print(f'epoch: {epoch} loss: {loss.item()}')\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "LfWaWVz3tlgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9Y2gfLrdusje",
        "outputId": "6be2a59b-96b5-48a6-bb5d-64ac98cec7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8d7ffadd30>]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('after training')\n",
        "z = []\n",
        "for g in train_loader:\n",
        "    g = g.to(device)\n",
        "    z.append(model(g.z, g.pos, g.edge_index, g.batch).detach().cpu().numpy())\n",
        "z = np.vstack(z)\n",
        "print(z.shape)\n",
        "cnt = 0\n",
        "for idx in range(z.shape[0]):\n",
        "    if np.any(z[idx] != 0): cnt+=1\n",
        "print(f'number of non-zero embeddings: {cnt}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_z-8uwQxSjF",
        "outputId": "08e83659-06a5-47f3-9a2e-79eb8452376c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after training\n",
            "(80, 1)\n",
            "number of non-zero embeddings: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = data_list[0].to(device)\n",
        "model(g.z, g.pos, g.edge_index, batch=None, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Revn_Ek5hIPp",
        "outputId": "ce2fbff8-a565-4c24-a428-c655fc46501e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4, 0, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 4, 0, 1, 2, 3],\n",
            "        [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]],\n",
            "       device='cuda:0')\n",
            "RBF: \n",
            " tensor([[ 2.8950,  4.4800,  4.0377,  1.7682, -1.3014, -3.7821],\n",
            "        [ 2.8950,  4.4800,  4.0375,  1.7679, -1.3017, -3.7823],\n",
            "        [ 2.8951,  4.4801,  4.0379,  1.7685, -1.3011, -3.7820],\n",
            "        [ 2.8950,  4.4800,  4.0376,  1.7680, -1.3016, -3.7822],\n",
            "        [ 2.8950,  4.4800,  4.0377,  1.7682, -1.3014, -3.7821],\n",
            "        [ 2.4540,  2.1368, -0.5934, -2.6535, -1.7171,  1.1584],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585],\n",
            "        [ 2.8950,  4.4800,  4.0375,  1.7679, -1.3017, -3.7823],\n",
            "        [ 2.4540,  2.1368, -0.5934, -2.6535, -1.7171,  1.1584],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585],\n",
            "        [ 2.8951,  4.4801,  4.0379,  1.7685, -1.3011, -3.7820],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585],\n",
            "        [ 2.8950,  4.4800,  4.0376,  1.7680, -1.3016, -3.7822],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585],\n",
            "        [ 2.4540,  2.1368, -0.5935, -2.6535, -1.7170,  1.1585]],\n",
            "       device='cuda:0', grad_fn=<MulBackward0>)\n",
            "SBF: \n",
            " tensor([[ 2.7453,  2.3904, -0.6639,  ...,  2.4545,  2.5710,  1.2858],\n",
            "        [ 2.7453,  2.3904, -0.6639,  ...,  2.4562,  2.5728,  1.2866],\n",
            "        [ 2.7453,  2.3904, -0.6639,  ...,  2.4552,  2.5717,  1.2860],\n",
            "        ...,\n",
            "        [ 5.2888,  8.1844,  7.3766,  ..., -1.9093, -4.0276, -7.0753],\n",
            "        [ 2.7453,  2.3904, -0.6639,  ...,  4.1034,  4.2982,  2.1494],\n",
            "        [ 2.7452,  2.3903, -0.6639,  ...,  4.1035,  4.2981,  2.1493]],\n",
            "       device='cuda:0')\n",
            "inside output block\n",
            "after lin_rbf tensor([[ 0.4475, -0.0885, -0.1986,  ...,  0.3498, -0.9429, -0.0327],\n",
            "        [ 0.4475, -0.0885, -0.1986,  ...,  0.3498, -0.9430, -0.0327],\n",
            "        [ 0.4475, -0.0885, -0.1986,  ...,  0.3497, -0.9429, -0.0327],\n",
            "        ...,\n",
            "        [ 0.2370,  0.0702,  0.0522,  ...,  0.1333,  0.0013,  0.0033],\n",
            "        [ 0.2370,  0.0702,  0.0522,  ...,  0.1333,  0.0013,  0.0033],\n",
            "        [ 0.2370,  0.0702,  0.0522,  ...,  0.1333,  0.0013,  0.0033]],\n",
            "       device='cuda:0', grad_fn=<MulBackward0>)\n",
            "after lins tensor([[-0.2240, -0.1442,  0.1901,  0.1125,  0.5997, -0.0061,  0.7153,  0.0965,\n",
            "         -0.1464,  0.0963, -0.0652, -0.1367, -0.2563, -0.0262, -0.1491,  0.2321,\n",
            "         -0.0611, -0.1918, -0.0275, -0.0729, -0.0300, -0.0482, -0.2197,  0.6240,\n",
            "          0.0400,  0.0557, -0.0548, -0.1703,  0.4687,  0.3492,  1.1094,  0.3328,\n",
            "          0.9426,  0.8788,  0.3425, -0.1368, -0.2481, -0.0161, -0.2453,  0.5255,\n",
            "         -0.2716,  0.2476, -0.0639, -0.2784, -0.1017,  0.2856,  0.2411,  0.1125,\n",
            "         -0.2125,  0.4511,  0.2405,  0.0296,  0.6063, -0.0649, -0.1581, -0.1120,\n",
            "         -0.2562, -0.1608, -0.1080,  0.0335,  0.0746, -0.2050,  0.4568, -0.2428],\n",
            "        [ 0.0866, -0.0924,  0.3653,  0.1048,  0.6111, -0.1547,  0.0595,  0.3749,\n",
            "          0.3527,  0.3040, -0.2584, -0.2285, -0.1760,  0.0057,  0.1209, -0.2176,\n",
            "         -0.0808,  0.1451,  0.0178,  0.3353,  0.0782, -0.0691, -0.0335,  0.0924,\n",
            "          0.0614, -0.0611, -0.1215, -0.1078,  0.3281,  0.1856,  0.7601,  0.1480,\n",
            "          0.1038,  0.3216,  0.3609,  0.4284,  0.0013, -0.0689, -0.0718, -0.1190,\n",
            "         -0.0200,  0.0513, -0.0274, -0.1951, -0.1785,  0.1959, -0.0030,  0.5772,\n",
            "          0.2667, -0.1663,  0.2291,  0.1450, -0.0852, -0.0773,  0.1816, -0.1182,\n",
            "          0.0134,  0.1729, -0.2329, -0.1424,  0.0606, -0.0419,  0.3414, -0.1782],\n",
            "        [ 0.0866, -0.0924,  0.3653,  0.1049,  0.6112, -0.1548,  0.0595,  0.3749,\n",
            "          0.3527,  0.3040, -0.2584, -0.2285, -0.1760,  0.0058,  0.1209, -0.2176,\n",
            "         -0.0808,  0.1451,  0.0177,  0.3353,  0.0782, -0.0691, -0.0335,  0.0923,\n",
            "          0.0613, -0.0611, -0.1215, -0.1078,  0.3281,  0.1856,  0.7601,  0.1480,\n",
            "          0.1038,  0.3216,  0.3609,  0.4284,  0.0013, -0.0689, -0.0718, -0.1190,\n",
            "         -0.0200,  0.0512, -0.0274, -0.1951, -0.1785,  0.1959, -0.0030,  0.5773,\n",
            "          0.2667, -0.1663,  0.2291,  0.1450, -0.0852, -0.0773,  0.1817, -0.1182,\n",
            "          0.0134,  0.1729, -0.2329, -0.1424,  0.0606, -0.0419,  0.3414, -0.1782],\n",
            "        [ 0.0866, -0.0924,  0.3653,  0.1048,  0.6111, -0.1547,  0.0595,  0.3749,\n",
            "          0.3527,  0.3040, -0.2584, -0.2285, -0.1760,  0.0057,  0.1209, -0.2176,\n",
            "         -0.0808,  0.1451,  0.0178,  0.3353,  0.0782, -0.0691, -0.0335,  0.0924,\n",
            "          0.0614, -0.0611, -0.1215, -0.1078,  0.3281,  0.1856,  0.7602,  0.1480,\n",
            "          0.1037,  0.3216,  0.3609,  0.4283,  0.0013, -0.0689, -0.0718, -0.1190,\n",
            "         -0.0200,  0.0513, -0.0274, -0.1951, -0.1785,  0.1959, -0.0030,  0.5772,\n",
            "          0.2667, -0.1663,  0.2291,  0.1450, -0.0852, -0.0773,  0.1816, -0.1182,\n",
            "          0.0134,  0.1729, -0.2328, -0.1424,  0.0606, -0.0419,  0.3414, -0.1782],\n",
            "        [ 0.0866, -0.0924,  0.3653,  0.1049,  0.6111, -0.1548,  0.0595,  0.3749,\n",
            "          0.3527,  0.3040, -0.2584, -0.2285, -0.1760,  0.0057,  0.1209, -0.2176,\n",
            "         -0.0808,  0.1451,  0.0177,  0.3353,  0.0782, -0.0691, -0.0335,  0.0923,\n",
            "          0.0613, -0.0611, -0.1215, -0.1078,  0.3281,  0.1856,  0.7601,  0.1480,\n",
            "          0.1038,  0.3216,  0.3609,  0.4284,  0.0013, -0.0689, -0.0718, -0.1190,\n",
            "         -0.0200,  0.0513, -0.0274, -0.1951, -0.1785,  0.1959, -0.0030,  0.5773,\n",
            "          0.2667, -0.1663,  0.2291,  0.1450, -0.0852, -0.0773,  0.1817, -0.1182,\n",
            "          0.0134,  0.1729, -0.2329, -0.1424,  0.0606, -0.0419,  0.3414, -0.1782]],\n",
            "       device='cuda:0', grad_fn=<MulBackward0>)\n",
            "final output tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
            "output after embedding layer\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
            "inside output block\n",
            "after lin_rbf tensor([[ 0.0779, -0.0804, -0.6166,  ..., -0.4060,  0.9741,  0.0098],\n",
            "        [ 0.0779, -0.0806, -0.6166,  ..., -0.4060,  0.9744,  0.0098],\n",
            "        [ 0.0779, -0.0802, -0.6166,  ..., -0.4060,  0.9737,  0.0099],\n",
            "        ...,\n",
            "        [-0.5834,  0.0644, -0.4233,  ..., -0.0042, -0.7343,  0.0756],\n",
            "        [-0.5834,  0.0642, -0.4233,  ..., -0.0042, -0.7343,  0.0757],\n",
            "        [-0.5833,  0.0645, -0.4233,  ..., -0.0042, -0.7343,  0.0755]],\n",
            "       device='cuda:0', grad_fn=<MulBackward0>)\n",
            "after lins tensor([[-1.9615e-01, -2.7845e-01,  1.4515e+00,  6.3340e-03,  2.3249e+00,\n",
            "         -2.5252e-01,  1.0773e+00,  2.3275e+00, -2.7830e-01, -2.7204e-01,\n",
            "          1.8450e+00,  1.9841e+00, -2.6996e-01, -2.7460e-01,  9.4007e-01,\n",
            "         -2.1929e-01,  3.9978e-01, -2.7831e-01,  9.1953e-01, -2.4872e-01,\n",
            "          4.8763e-01, -1.7910e-01, -7.5192e-02,  1.7587e+00,  1.2464e+00,\n",
            "         -4.7886e-02,  3.0503e-01,  1.4934e+00, -2.1036e-01, -2.7556e-01,\n",
            "         -1.6744e-01, -4.8705e-02,  4.3928e-01,  1.5464e+00,  3.0714e+00,\n",
            "          6.9069e-01,  2.7411e+00, -2.3890e-01,  5.8915e-01, -2.7790e-01,\n",
            "          5.2749e-01, -1.5747e-01, -2.3720e-01, -2.1409e-01, -1.0519e-01,\n",
            "         -1.5110e-01,  1.3615e+00, -1.1499e-01,  1.4868e+00,  3.3104e-01,\n",
            "          6.3445e-01, -2.6712e-01,  1.6219e+00, -2.4070e-01, -1.4024e-01,\n",
            "          2.1465e-02,  2.9901e-01,  3.2644e+00, -2.2095e-01, -2.0184e-01,\n",
            "         -1.9020e-01,  9.1891e-01, -2.7363e-01,  1.0533e-02],\n",
            "        [-2.2007e-01, -1.6178e-02,  7.9361e+00,  1.5157e-02,  7.9279e+00,\n",
            "         -2.6874e-02,  4.4631e+00,  9.3767e+00, -1.3177e-01, -1.4041e-01,\n",
            "          3.2468e+00,  6.6242e+00, -2.4371e-01, -1.8380e-01, -1.6372e-01,\n",
            "         -2.4599e-01,  1.1719e+00,  4.4129e+00,  1.1388e+00, -2.1710e-01,\n",
            "         -1.8612e-01, -1.9507e-01,  1.2120e+00,  9.5714e+00,  9.6178e+00,\n",
            "         -5.5598e-02,  6.9889e-01, -4.4093e-02, -7.6496e-03, -2.9061e-02,\n",
            "          2.4677e+00, -2.6964e-01,  5.2082e+00,  1.7252e+00,  8.8396e+00,\n",
            "          1.4703e-01, -2.7844e-01, -2.1412e-03,  2.4391e+00, -1.7220e-01,\n",
            "          3.5443e+00, -1.0965e-01, -2.7125e-01, -1.4131e-02,  4.2206e-01,\n",
            "         -8.3515e-02,  5.3595e+00, -1.9447e-01,  2.1185e+00,  3.8193e+00,\n",
            "          2.1899e+00, -2.8731e-02, -2.6545e-01, -6.6480e-02,  4.4978e-01,\n",
            "          7.1433e-01, -2.7627e-01,  1.4644e+00, -3.9865e-04, -2.1828e-01,\n",
            "         -2.0621e-03,  3.2260e+00, -2.3387e-01, -5.4229e-05],\n",
            "        [-2.2008e-01, -1.6173e-02,  7.9359e+00,  1.5008e-02,  7.9277e+00,\n",
            "         -2.6867e-02,  4.4630e+00,  9.3764e+00, -1.3180e-01, -1.4042e-01,\n",
            "          3.2470e+00,  6.6243e+00, -2.4371e-01, -1.8381e-01, -1.6362e-01,\n",
            "         -2.4600e-01,  1.1719e+00,  4.4123e+00,  1.1392e+00, -2.1709e-01,\n",
            "         -1.8608e-01, -1.9510e-01,  1.2118e+00,  9.5717e+00,  9.6175e+00,\n",
            "         -5.5610e-02,  6.9892e-01, -4.3997e-02, -7.6512e-03, -2.9061e-02,\n",
            "          2.4679e+00, -2.6963e-01,  5.2082e+00,  1.7250e+00,  8.8398e+00,\n",
            "          1.4688e-01, -2.7844e-01, -2.1407e-03,  2.4389e+00, -1.7220e-01,\n",
            "          3.5443e+00, -1.0965e-01, -2.7126e-01, -1.4130e-02,  4.2221e-01,\n",
            "         -8.3516e-02,  5.3593e+00, -1.9441e-01,  2.1186e+00,  3.8194e+00,\n",
            "          2.1902e+00, -2.8739e-02, -2.6545e-01, -6.6471e-02,  4.4990e-01,\n",
            "          7.1433e-01, -2.7627e-01,  1.4642e+00, -3.9857e-04, -2.1831e-01,\n",
            "         -2.0614e-03,  3.2262e+00, -2.3385e-01, -5.4239e-05],\n",
            "        [-2.2004e-01, -1.6185e-02,  7.9363e+00,  1.5305e-02,  7.9281e+00,\n",
            "         -2.6880e-02,  4.4631e+00,  9.3769e+00, -1.3176e-01, -1.4041e-01,\n",
            "          3.2466e+00,  6.6241e+00, -2.4372e-01, -1.8380e-01, -1.6383e-01,\n",
            "         -2.4598e-01,  1.1718e+00,  4.4134e+00,  1.1384e+00, -2.1711e-01,\n",
            "         -1.8616e-01, -1.9504e-01,  1.2122e+00,  9.5711e+00,  9.6180e+00,\n",
            "         -5.5591e-02,  6.9886e-01, -4.4203e-02, -7.6485e-03, -2.9059e-02,\n",
            "          2.4675e+00, -2.6966e-01,  5.2083e+00,  1.7255e+00,  8.8395e+00,\n",
            "          1.4721e-01, -2.7844e-01, -2.1417e-03,  2.4392e+00, -1.7220e-01,\n",
            "          3.5442e+00, -1.0965e-01, -2.7125e-01, -1.4132e-02,  4.2200e-01,\n",
            "         -8.3519e-02,  5.3598e+00, -1.9451e-01,  2.1182e+00,  3.8193e+00,\n",
            "          2.1897e+00, -2.8723e-02, -2.6545e-01, -6.6492e-02,  4.4969e-01,\n",
            "          7.1438e-01, -2.7627e-01,  1.4646e+00, -3.9878e-04, -2.1825e-01,\n",
            "         -2.0630e-03,  3.2260e+00, -2.3389e-01, -5.4220e-05],\n",
            "        [-2.2007e-01, -1.6176e-02,  7.9360e+00,  1.5066e-02,  7.9277e+00,\n",
            "         -2.6869e-02,  4.4630e+00,  9.3764e+00, -1.3180e-01, -1.4042e-01,\n",
            "          3.2470e+00,  6.6242e+00, -2.4372e-01, -1.8381e-01, -1.6367e-01,\n",
            "         -2.4599e-01,  1.1718e+00,  4.4125e+00,  1.1391e+00, -2.1709e-01,\n",
            "         -1.8610e-01, -1.9509e-01,  1.2119e+00,  9.5716e+00,  9.6176e+00,\n",
            "         -5.5608e-02,  6.9891e-01, -4.4041e-02, -7.6510e-03, -2.9060e-02,\n",
            "          2.4679e+00, -2.6963e-01,  5.2082e+00,  1.7251e+00,  8.8398e+00,\n",
            "          1.4694e-01, -2.7844e-01, -2.1408e-03,  2.4389e+00, -1.7220e-01,\n",
            "          3.5443e+00, -1.0965e-01, -2.7126e-01, -1.4131e-02,  4.2221e-01,\n",
            "         -8.3519e-02,  5.3594e+00, -1.9442e-01,  2.1185e+00,  3.8194e+00,\n",
            "          2.1901e+00, -2.8736e-02, -2.6544e-01, -6.6476e-02,  4.4987e-01,\n",
            "          7.1437e-01, -2.7627e-01,  1.4643e+00, -3.9863e-04, -2.1830e-01,\n",
            "         -2.0618e-03,  3.2262e+00, -2.3386e-01, -5.4236e-05]], device='cuda:0',\n",
            "       grad_fn=<MulBackward0>)\n",
            "final output tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
            "output after interaction layer\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "state after interaction layer\n",
            "tensor([[ 0.0768, -0.0614,  0.6949,  ...,  0.3402,  2.0294,  0.1453],\n",
            "        [ 0.0768, -0.0615,  0.6949,  ...,  0.3402,  2.0295,  0.1453],\n",
            "        [ 0.0768, -0.0612,  0.6949,  ...,  0.3402,  2.0293,  0.1454],\n",
            "        ...,\n",
            "        [-0.5237, -0.1075,  1.8094,  ..., -0.0349, -0.3692, -0.1648],\n",
            "        [-0.5238, -0.1072,  1.8093,  ..., -0.0350, -0.3692, -0.1650],\n",
            "        [-0.5237, -0.1077,  1.8094,  ..., -0.0349, -0.3692, -0.1647]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "inside output block\n",
            "after lin_rbf tensor([[-4.1065e-01, -2.8815e-02,  1.4279e+00,  ...,  2.3780e+00,\n",
            "          1.3508e+00,  2.3160e+00],\n",
            "        [-4.1057e-01, -2.8816e-02,  1.4282e+00,  ...,  2.3781e+00,\n",
            "          1.3515e+00,  2.3161e+00],\n",
            "        [-4.1068e-01, -2.8812e-02,  1.4276e+00,  ...,  2.3781e+00,\n",
            "          1.3501e+00,  2.3159e+00],\n",
            "        ...,\n",
            "        [ 4.2552e+00,  5.6927e+00,  5.7143e+01,  ..., -2.2121e+01,\n",
            "          1.6454e+01,  1.3061e+01],\n",
            "        [ 4.2553e+00,  5.6915e+00,  5.7135e+01,  ..., -2.2117e+01,\n",
            "          1.6451e+01,  1.3059e+01],\n",
            "        [ 4.2552e+00,  5.6939e+00,  5.7151e+01,  ..., -2.2124e+01,\n",
            "          1.6457e+01,  1.3063e+01]], device='cuda:0', grad_fn=<MulBackward0>)\n",
            "after lins tensor([[ 1.2274e+00,  1.0358e+00, -1.8319e-01,  1.7008e+00,  4.6683e+00,\n",
            "          1.1457e+00,  3.2220e+00,  1.8857e+00,  5.6850e-01,  1.4456e+00,\n",
            "          5.2378e+00, -6.8155e-02, -4.0980e-02, -1.8799e-01,  9.5904e-01,\n",
            "          2.2313e+00, -1.0776e-01,  2.5868e+00, -4.8429e-02,  3.5255e+00,\n",
            "         -1.2926e-01, -1.2740e-02,  2.3633e+00,  7.7839e-01,  4.0925e-01,\n",
            "          3.0908e-01,  5.8131e-01,  4.2491e+00,  2.4003e+00,  1.4739e-01,\n",
            "          6.5726e-01,  3.6469e-01,  1.4380e+00,  3.7061e+00,  1.7641e+00,\n",
            "         -2.6650e-01, -5.3362e-02,  8.1105e-01, -1.4310e-01, -2.5511e-01,\n",
            "          6.1620e-01,  3.1381e+00, -2.4430e-01, -2.4278e-01,  5.7249e-02,\n",
            "          3.4664e+00, -1.6402e-01,  1.4271e+00, -2.6976e-01,  4.9285e-01,\n",
            "          2.1276e+00,  3.3643e-01,  4.3402e-01, -2.7796e-01, -2.4893e-01,\n",
            "          3.8681e+00,  5.3116e+00, -2.3233e-01,  8.6947e-02,  3.1855e+00,\n",
            "         -1.6615e-01, -9.8033e-02, -2.6003e-01, -9.3039e-02],\n",
            "        [ 8.8844e+01,  2.2706e+01,  3.4718e+01,  4.9021e+01,  6.4671e+01,\n",
            "         -1.5700e-22, -2.7819e-01,  5.4156e+01,  6.5565e+00,  2.4068e+01,\n",
            "          2.3687e+00, -9.2233e-06, -2.7375e-01, -7.1419e-08,  1.9695e+01,\n",
            "          9.5931e-01, -6.4462e-25,  4.4540e+01, -6.9405e-05,  6.7165e+01,\n",
            "         -2.4303e-24,  6.5912e+01,  1.3333e+01, -1.2647e-03,  3.1600e+01,\n",
            "          1.9401e+00,  4.8499e+01,  3.9376e+01,  4.2219e+01, -1.5671e-16,\n",
            "          9.1932e+00, -3.1247e-25,  1.1638e+01,  6.2334e+01, -1.1044e-11,\n",
            "         -2.4845e-01, -2.5491e-01, -3.6356e-02, -3.2122e-16, -2.9570e-07,\n",
            "         -2.5187e-01,  4.7345e+01,  4.0537e+01, -1.1741e-03, -4.7069e-13,\n",
            "          3.7092e+01, -1.1847e-03,  2.0143e+00, -2.2302e-26,  2.2782e+01,\n",
            "          4.2584e+01,  1.1445e+01,  1.3519e+01, -4.4514e-08, -1.7469e-10,\n",
            "         -4.0888e-15,  2.9716e+01, -1.4926e-07,  1.5721e+00, -3.2492e-11,\n",
            "         -5.3154e-19,  3.4332e+00,  2.8591e+00,  6.9102e+00],\n",
            "        [ 8.8844e+01,  2.2707e+01,  3.4717e+01,  4.9022e+01,  6.4673e+01,\n",
            "         -1.5643e-22, -2.7818e-01,  5.4157e+01,  6.5557e+00,  2.4067e+01,\n",
            "          2.3694e+00, -9.2195e-06, -2.7374e-01, -7.1327e-08,  1.9694e+01,\n",
            "          9.5852e-01, -6.4227e-25,  4.4540e+01, -6.9494e-05,  6.7165e+01,\n",
            "         -2.4316e-24,  6.5913e+01,  1.3334e+01, -1.2662e-03,  3.1601e+01,\n",
            "          1.9412e+00,  4.8500e+01,  3.9376e+01,  4.2219e+01, -1.5681e-16,\n",
            "          9.1941e+00, -3.1186e-25,  1.1637e+01,  6.2336e+01, -1.1036e-11,\n",
            "         -2.4858e-01, -2.5499e-01, -3.6288e-02, -3.2082e-16, -2.9611e-07,\n",
            "         -2.5176e-01,  4.7347e+01,  4.0540e+01, -1.1747e-03, -4.7037e-13,\n",
            "          3.7093e+01, -1.1838e-03,  2.0130e+00, -2.2284e-26,  2.2782e+01,\n",
            "          4.2583e+01,  1.1445e+01,  1.3518e+01, -4.4478e-08, -1.7477e-10,\n",
            "         -4.0838e-15,  2.9716e+01, -1.4911e-07,  1.5724e+00, -3.2491e-11,\n",
            "         -5.3181e-19,  3.4328e+00,  2.8594e+00,  6.9097e+00],\n",
            "        [ 8.8842e+01,  2.2704e+01,  3.4720e+01,  4.9019e+01,  6.4670e+01,\n",
            "         -1.5754e-22, -2.7823e-01,  5.4152e+01,  6.5564e+00,  2.4069e+01,\n",
            "          2.3683e+00, -9.2109e-06, -2.7379e-01, -7.1513e-08,  1.9695e+01,\n",
            "          9.6084e-01, -6.4647e-25,  4.4540e+01, -6.9310e-05,  6.7163e+01,\n",
            "         -2.4343e-24,  6.5911e+01,  1.3330e+01, -1.2637e-03,  3.1600e+01,\n",
            "          1.9413e+00,  4.8497e+01,  3.9376e+01,  4.2216e+01, -1.5681e-16,\n",
            "          9.1919e+00, -3.1386e-25,  1.1640e+01,  6.2333e+01, -1.1048e-11,\n",
            "         -2.4848e-01, -2.5483e-01, -3.6442e-02, -3.2212e-16, -2.9511e-07,\n",
            "         -2.5186e-01,  4.7343e+01,  4.0534e+01, -1.1742e-03, -4.7078e-13,\n",
            "          3.7091e+01, -1.1871e-03,  2.0168e+00, -2.2355e-26,  2.2779e+01,\n",
            "          4.2584e+01,  1.1447e+01,  1.3519e+01, -4.4466e-08, -1.7441e-10,\n",
            "         -4.0946e-15,  2.9717e+01, -1.4952e-07,  1.5734e+00, -3.2541e-11,\n",
            "         -5.3209e-19,  3.4326e+00,  2.8586e+00,  6.9090e+00],\n",
            "        [ 8.8843e+01,  2.2707e+01,  3.4718e+01,  4.9021e+01,  6.4673e+01,\n",
            "         -1.5663e-22, -2.7820e-01,  5.4155e+01,  6.5554e+00,  2.4068e+01,\n",
            "          2.3693e+00, -9.2110e-06, -2.7375e-01, -7.1355e-08,  1.9694e+01,\n",
            "          9.5930e-01, -6.4282e-25,  4.4540e+01, -6.9461e-05,  6.7164e+01,\n",
            "         -2.4343e-24,  6.5913e+01,  1.3333e+01, -1.2659e-03,  3.1600e+01,\n",
            "          1.9421e+00,  4.8498e+01,  3.9376e+01,  4.2218e+01, -1.5690e-16,\n",
            "          9.1936e+00, -3.1256e-25,  1.1637e+01,  6.2336e+01, -1.1036e-11,\n",
            "         -2.4863e-01, -2.5497e-01, -3.6327e-02, -3.2129e-16, -2.9587e-07,\n",
            "         -2.5173e-01,  4.7346e+01,  4.0539e+01, -1.1749e-03, -4.7035e-13,\n",
            "          3.7092e+01, -1.1851e-03,  2.0141e+00, -2.2311e-26,  2.2781e+01,\n",
            "          4.2583e+01,  1.1446e+01,  1.3518e+01, -4.4440e-08, -1.7464e-10,\n",
            "         -4.0863e-15,  2.9716e+01, -1.4923e-07,  1.5733e+00, -3.2520e-11,\n",
            "         -5.3222e-19,  3.4324e+00,  2.8592e+00,  6.9088e+00]], device='cuda:0',\n",
            "       grad_fn=<MulBackward0>)\n",
            "final output tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
            "output after interaction layer\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "state after interaction layer\n",
            "tensor([[ 0.4936, -0.1068,  2.5027,  ...,  3.7611,  2.6041,  0.9113],\n",
            "        [ 0.4935, -0.1068,  2.5028,  ...,  3.7614,  2.6042,  0.9113],\n",
            "        [ 0.4936, -0.1068,  2.5026,  ...,  3.7609,  2.6039,  0.9112],\n",
            "        ...,\n",
            "        [ 5.9296, 27.3180, 33.4242,  ..., 68.8835, 25.0325, 25.3627],\n",
            "        [ 5.9297, 27.3116, 33.4191,  ..., 68.8733, 25.0277, 25.3582],\n",
            "        [ 5.9295, 27.3238, 33.4287,  ..., 68.8932, 25.0366, 25.3659]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "inside output block\n",
            "after lin_rbf tensor([[   4.3893,   77.3867,   34.7422,  ..., -183.5678,    9.4070,\n",
            "          -50.6109],\n",
            "        [   4.3910,   77.3921,   34.7352,  ..., -183.5383,    9.3976,\n",
            "          -50.6237],\n",
            "        [   4.3873,   77.3804,   34.7477,  ..., -183.5912,    9.4153,\n",
            "          -50.5837],\n",
            "        ...,\n",
            "        [ -15.2955,  157.3318, -226.4875,  ...,  109.2504,  -31.1407,\n",
            "           64.3751],\n",
            "        [ -15.2939,  157.3243, -226.4867,  ...,  109.2347,  -31.1356,\n",
            "           64.3711],\n",
            "        [ -15.2970,  157.3401, -226.4879,  ...,  109.2656,  -31.1552,\n",
            "           64.3754]], device='cuda:0', grad_fn=<MulBackward0>)\n",
            "after lins tensor([[ 6.8563e+01, -0.0000e+00,  2.3824e+02,  1.0838e+02, -0.0000e+00,\n",
            "         -0.0000e+00,  2.5040e+02, -0.0000e+00, -0.0000e+00, -1.7735e-12,\n",
            "         -4.8151e-32,  1.0517e+02,  1.4958e+01, -0.0000e+00,  2.4310e+02,\n",
            "         -0.0000e+00,  2.4126e+02,  5.0359e+02,  7.5426e+01, -0.0000e+00,\n",
            "          1.3786e+00, -0.0000e+00,  9.3156e+00, -4.7043e-36,  3.8415e+01,\n",
            "          5.5722e+01,  9.1536e+01,  2.2528e+01,  8.7350e+00,  3.7829e+02,\n",
            "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.6868e+02,\n",
            "          9.3062e+01,  9.0316e+02,  7.6880e+01,  4.6740e+02, -0.0000e+00,\n",
            "          2.3416e+02, -0.0000e+00,  1.7267e+02, -0.0000e+00,  7.1235e+01,\n",
            "          7.2071e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  4.6338e+02,\n",
            "          1.7295e+02, -0.0000e+00,  5.0257e+01, -9.0120e-16, -3.4500e-04,\n",
            "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  5.7630e+01,  2.6675e+02,\n",
            "         -0.0000e+00, -0.0000e+00,  9.5206e+01, -0.0000e+00],\n",
            "        [-1.7055e-07,  1.1441e+02,  7.7541e+01, -2.4372e-12, -2.0510e-32,\n",
            "         -4.4853e-05,  4.5376e+01,  3.4113e+00,  2.8300e+01,  5.1749e+01,\n",
            "         -8.7084e-04, -7.7047e-13,  8.5404e+01, -2.3118e-13,  3.3336e+01,\n",
            "         -6.3940e-37,  7.3736e+01,  1.4178e+02,  1.3033e+02, -2.8756e-37,\n",
            "         -2.7773e-17, -0.0000e+00, -7.3258e-29, -9.6149e-25, -1.9829e-32,\n",
            "          1.2904e+02, -2.9863e-10,  5.9221e+01, -0.0000e+00,  1.4081e+02,\n",
            "          1.4916e+01,  5.8860e+01,  2.2085e+01, -4.5076e-07,  2.6446e+02,\n",
            "          5.5910e+01,  1.2920e+02, -0.0000e+00,  1.0323e+02,  1.7885e+02,\n",
            "         -1.1226e-09, -0.0000e+00, -8.8079e-22,  4.7864e+01,  5.8669e+01,\n",
            "          1.5617e+01, -7.5069e-22, -9.3056e-33, -1.4603e-05,  2.3644e+02,\n",
            "          8.9601e+01, -1.3394e-28, -0.0000e+00,  8.8571e+01,  6.1366e+01,\n",
            "          3.9947e+00,  6.6985e+01, -0.0000e+00, -3.8039e-10, -3.2457e-26,\n",
            "          3.1753e+01, -0.0000e+00, -0.0000e+00, -2.1298e-08],\n",
            "        [-1.7032e-07,  1.1442e+02,  7.7541e+01, -2.4302e-12, -2.0470e-32,\n",
            "         -4.4770e-05,  4.5381e+01,  3.4120e+00,  2.8300e+01,  5.1746e+01,\n",
            "         -8.7355e-04, -7.7053e-13,  8.5408e+01, -2.3105e-13,  3.3336e+01,\n",
            "         -6.3659e-37,  7.3734e+01,  1.4178e+02,  1.3033e+02, -2.8755e-37,\n",
            "         -2.7677e-17, -0.0000e+00, -7.2988e-29, -9.5991e-25, -1.9751e-32,\n",
            "          1.2904e+02, -2.9886e-10,  5.9220e+01, -0.0000e+00,  1.4081e+02,\n",
            "          1.4919e+01,  5.8861e+01,  2.2085e+01, -4.5051e-07,  2.6446e+02,\n",
            "          5.5909e+01,  1.2920e+02, -0.0000e+00,  1.0322e+02,  1.7885e+02,\n",
            "         -1.1186e-09, -0.0000e+00, -8.8136e-22,  4.7866e+01,  5.8669e+01,\n",
            "          1.5611e+01, -7.5195e-22, -9.2901e-33, -1.4549e-05,  2.3644e+02,\n",
            "          8.9602e+01, -1.3355e-28, -0.0000e+00,  8.8568e+01,  6.1365e+01,\n",
            "          3.9982e+00,  6.6983e+01, -0.0000e+00, -3.7979e-10, -3.2485e-26,\n",
            "          3.1752e+01, -0.0000e+00, -0.0000e+00, -2.1326e-08],\n",
            "        [-1.6964e-07,  1.1442e+02,  7.7545e+01, -2.4442e-12, -2.0498e-32,\n",
            "         -4.5255e-05,  4.5369e+01,  3.4117e+00,  2.8303e+01,  5.1754e+01,\n",
            "         -8.6681e-04, -7.7369e-13,  8.5403e+01, -2.3244e-13,  3.3344e+01,\n",
            "         -6.4622e-37,  7.3734e+01,  1.4179e+02,  1.3034e+02, -2.8484e-37,\n",
            "         -2.7878e-17, -0.0000e+00, -7.3633e-29, -9.6171e-25, -1.9870e-32,\n",
            "          1.2904e+02, -2.9670e-10,  5.9217e+01, -0.0000e+00,  1.4081e+02,\n",
            "          1.4912e+01,  5.8861e+01,  2.2086e+01, -4.4953e-07,  2.6446e+02,\n",
            "          5.5917e+01,  1.2920e+02, -0.0000e+00,  1.0323e+02,  1.7885e+02,\n",
            "         -1.1231e-09, -0.0000e+00, -8.7336e-22,  4.7866e+01,  5.8677e+01,\n",
            "          1.5622e+01, -7.4855e-22, -9.3151e-33, -1.4662e-05,  2.3644e+02,\n",
            "          8.9600e+01, -1.3370e-28, -0.0000e+00,  8.8568e+01,  6.1357e+01,\n",
            "          3.9938e+00,  6.6992e+01, -0.0000e+00, -3.7998e-10, -3.2582e-26,\n",
            "          3.1751e+01, -0.0000e+00, -0.0000e+00, -2.1228e-08],\n",
            "        [-1.6967e-07,  1.1442e+02,  7.7544e+01, -2.4332e-12, -2.0453e-32,\n",
            "         -4.4998e-05,  4.5378e+01,  3.4126e+00,  2.8301e+01,  5.1748e+01,\n",
            "         -8.7154e-04, -7.7261e-13,  8.5408e+01, -2.3178e-13,  3.3341e+01,\n",
            "         -6.3995e-37,  7.3733e+01,  1.4178e+02,  1.3033e+02, -2.8578e-37,\n",
            "         -2.7719e-17, -0.0000e+00, -7.3143e-29, -9.5957e-25, -1.9756e-32,\n",
            "          1.2904e+02, -2.9775e-10,  5.9217e+01, -0.0000e+00,  1.4081e+02,\n",
            "          1.4917e+01,  5.8862e+01,  2.2086e+01, -4.4961e-07,  2.6446e+02,\n",
            "          5.5913e+01,  1.2920e+02, -0.0000e+00,  1.0322e+02,  1.7886e+02,\n",
            "         -1.1179e-09, -0.0000e+00, -8.7667e-22,  4.7868e+01,  5.8674e+01,\n",
            "          1.5614e+01, -7.5084e-22, -9.2894e-33, -1.4571e-05,  2.3644e+02,\n",
            "          8.9602e+01, -1.3331e-28, -0.0000e+00,  8.8565e+01,  6.1359e+01,\n",
            "          3.9989e+00,  6.6987e+01, -0.0000e+00, -3.7947e-10, -3.2569e-26,\n",
            "          3.1751e+01, -0.0000e+00, -0.0000e+00, -2.1285e-08]], device='cuda:0',\n",
            "       grad_fn=<MulBackward0>)\n",
            "final output tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
            "output after interaction layer\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "state after interaction layer\n",
            "tensor([[ 34.7496, 333.8991, 320.0063,  ..., 123.8133,  54.1367,  20.9130],\n",
            "        [ 34.7498, 333.9094, 320.0213,  ..., 123.8155,  54.1437,  20.9179],\n",
            "        [ 34.7469, 333.8847, 319.9785,  ..., 123.8075,  54.1245,  20.9021],\n",
            "        ...,\n",
            "        [ 60.0981, 290.0114, 277.2976,  ...,  68.8835,  26.8710, 131.5666],\n",
            "        [ 60.0936, 289.9993, 277.2968,  ...,  68.8733,  26.8664, 131.5637],\n",
            "        [ 60.1034, 290.0258, 277.2979,  ...,  68.8932,  26.8836, 131.5645]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "inside output block\n",
            "after lin_rbf tensor([[ -521.8988,  -588.2338,  -435.8638,  ...,  -258.0645,  1075.8815,\n",
            "         -1607.8074],\n",
            "        [ -521.9255,  -588.1547,  -435.8557,  ...,  -258.0703,  1076.2651,\n",
            "         -1607.9453],\n",
            "        [ -521.8880,  -588.3141,  -435.8626,  ...,  -258.0720,  1075.5072,\n",
            "         -1607.5491],\n",
            "        ...,\n",
            "        [   -3.7646,   269.3267,   144.8706,  ...,    94.4134,   875.7277,\n",
            "           319.3557],\n",
            "        [   -3.7650,   269.3157,   144.8839,  ...,    94.4278,   875.6918,\n",
            "           319.3609],\n",
            "        [   -3.7647,   269.3400,   144.8687,  ...,    94.4271,   875.7844,\n",
            "           319.3557]], device='cuda:0', grad_fn=<MulBackward0>)\n",
            "after lins tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00,  2.9283e+03, -0.0000e+00,\n",
            "          1.0916e+03,  4.4833e+03,  2.9801e+03, -0.0000e+00,  3.9913e+03,\n",
            "         -0.0000e+00,  1.7836e+03,  1.1092e+03,  4.9102e+02, -1.1946e-30,\n",
            "          1.5027e+03, -0.0000e+00, -0.0000e+00,  2.7713e+02,  2.2594e+03,\n",
            "          3.8193e+02,  4.2467e+02,  1.1762e+02,  2.4183e+03,  2.5424e+03,\n",
            "         -0.0000e+00,  3.6069e+03,  5.8008e+02,  2.0253e+03, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00,  1.0120e+03,  1.4137e+03, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  3.1967e+02,\n",
            "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.6484e+03, -0.0000e+00,\n",
            "         -0.0000e+00,  2.1590e+03, -0.0000e+00,  1.6769e+03, -0.0000e+00,\n",
            "          1.3286e+03,  1.7467e+03, -0.0000e+00,  1.9106e+03, -0.0000e+00,\n",
            "          1.6810e+03, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "          2.7219e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
            "        [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.9275e+03, -0.0000e+00,\n",
            "          1.9698e+03,  4.1653e+03,  2.8806e+03, -0.0000e+00,  1.8117e+03,\n",
            "         -0.0000e+00, -0.0000e+00,  4.9920e+02,  4.1980e+02, -0.0000e+00,\n",
            "         -0.0000e+00,  4.8758e+02, -0.0000e+00,  2.8893e+02,  1.7779e+03,\n",
            "         -0.0000e+00,  1.0763e+03, -8.0985e-25,  1.7775e+03,  2.3905e+03,\n",
            "         -0.0000e+00,  1.9013e+03, -0.0000e+00,  2.3309e+03, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00,  2.8803e+03,  3.5017e+02, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.0932e+03,\n",
            "          1.4886e+02, -0.0000e+00, -0.0000e+00,  2.1194e+03, -0.0000e+00,\n",
            "         -2.3361e-17,  2.2596e+03, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "          9.2924e+02,  8.6245e+02, -0.0000e+00,  1.3341e+03, -0.0000e+00,\n",
            "          6.0474e+02,  6.7252e+02, -0.0000e+00,  2.2897e+02, -0.0000e+00,\n",
            "          1.7364e+03,  1.7099e+02, -0.0000e+00, -0.0000e+00],\n",
            "        [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.9275e+03, -0.0000e+00,\n",
            "          1.9698e+03,  4.1654e+03,  2.8805e+03, -0.0000e+00,  1.8118e+03,\n",
            "         -0.0000e+00, -0.0000e+00,  4.9923e+02,  4.1971e+02, -0.0000e+00,\n",
            "         -0.0000e+00,  4.8784e+02, -0.0000e+00,  2.8910e+02,  1.7779e+03,\n",
            "         -0.0000e+00,  1.0760e+03, -7.4622e-25,  1.7774e+03,  2.3906e+03,\n",
            "         -0.0000e+00,  1.9014e+03, -0.0000e+00,  2.3311e+03, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00,  2.8805e+03,  3.4996e+02, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.0934e+03,\n",
            "          1.4873e+02, -0.0000e+00, -0.0000e+00,  2.1195e+03, -0.0000e+00,\n",
            "         -2.3261e-17,  2.2595e+03, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "          9.2922e+02,  8.6238e+02, -0.0000e+00,  1.3343e+03, -0.0000e+00,\n",
            "          6.0475e+02,  6.7241e+02, -0.0000e+00,  2.2907e+02, -0.0000e+00,\n",
            "          1.7365e+03,  1.7102e+02, -0.0000e+00, -0.0000e+00],\n",
            "        [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.9274e+03, -0.0000e+00,\n",
            "          1.9698e+03,  4.1652e+03,  2.8807e+03, -0.0000e+00,  1.8117e+03,\n",
            "         -0.0000e+00, -0.0000e+00,  4.9921e+02,  4.1987e+02, -0.0000e+00,\n",
            "         -0.0000e+00,  4.8733e+02, -0.0000e+00,  2.8864e+02,  1.7780e+03,\n",
            "         -0.0000e+00,  1.0766e+03, -8.7871e-25,  1.7776e+03,  2.3904e+03,\n",
            "         -0.0000e+00,  1.9012e+03, -0.0000e+00,  2.3307e+03, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00,  2.8802e+03,  3.5048e+02, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.0931e+03,\n",
            "          1.4904e+02, -0.0000e+00, -0.0000e+00,  2.1194e+03, -0.0000e+00,\n",
            "         -2.4161e-17,  2.2598e+03, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "          9.2924e+02,  8.6250e+02, -0.0000e+00,  1.3339e+03, -0.0000e+00,\n",
            "          6.0473e+02,  6.7266e+02, -0.0000e+00,  2.2889e+02, -0.0000e+00,\n",
            "          1.7364e+03,  1.7096e+02, -0.0000e+00, -0.0000e+00],\n",
            "        [-0.0000e+00, -0.0000e+00, -0.0000e+00,  1.9275e+03, -0.0000e+00,\n",
            "          1.9698e+03,  4.1653e+03,  2.8805e+03, -0.0000e+00,  1.8117e+03,\n",
            "         -0.0000e+00, -0.0000e+00,  4.9925e+02,  4.1974e+02, -0.0000e+00,\n",
            "         -0.0000e+00,  4.8775e+02, -0.0000e+00,  2.8896e+02,  1.7779e+03,\n",
            "         -0.0000e+00,  1.0761e+03, -7.6759e-25,  1.7774e+03,  2.3905e+03,\n",
            "         -0.0000e+00,  1.9014e+03, -0.0000e+00,  2.3310e+03, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00,  2.8804e+03,  3.5010e+02, -0.0000e+00,\n",
            "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.0933e+03,\n",
            "          1.4880e+02, -0.0000e+00, -0.0000e+00,  2.1194e+03, -0.0000e+00,\n",
            "         -2.3706e-17,  2.2596e+03, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
            "          9.2922e+02,  8.6240e+02, -0.0000e+00,  1.3342e+03, -0.0000e+00,\n",
            "          6.0475e+02,  6.7246e+02, -0.0000e+00,  2.2905e+02, -0.0000e+00,\n",
            "          1.7364e+03,  1.7101e+02, -0.0000e+00, -0.0000e+00]], device='cuda:0',\n",
            "       grad_fn=<MulBackward0>)\n",
            "final output tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<MmBackward0>)\n",
            "output after interaction layer\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "state after interaction layer\n",
            "tensor([[ 189.5818,  897.1332,  504.6469,  ...,  304.1627, 1582.3877,\n",
            "          832.9930],\n",
            "        [ 189.6008,  897.1472,  504.6717,  ...,  304.1564, 1582.4919,\n",
            "          833.0757],\n",
            "        [ 189.5688,  897.1237,  504.6121,  ...,  304.1843, 1582.2878,\n",
            "          832.8483],\n",
            "        ...,\n",
            "        [  73.3783,  290.0114,  313.5125,  ...,  187.8163,  506.7161,\n",
            "          519.6676],\n",
            "        [  73.3721,  289.9993,  313.5440,  ...,  187.8496,  506.6920,\n",
            "          519.6849],\n",
            "        [  73.3862,  290.0258,  313.5073,  ...,  187.8411,  506.7505,\n",
            "          519.6632]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Post dimenet: tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
            "Post summation: tensor([0.], device='cuda:0', grad_fn=<SumBackward1>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], device='cuda:0', grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimenet as a model"
      ],
      "metadata": {
        "id": "zaMBP2JAyG2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## parameters and model"
      ],
      "metadata": {
        "id": "_HpZNKiozHsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_list_raw = data.QM9('./data/QM9')\n",
        "N = 100\n",
        "data_list = [g for g in data_list_raw[:N] if g.x.shape[0] < 20]\n",
        "# Define the device (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model and datasets to the device\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "num_layers = 1\n",
        "out_channels = 2\n",
        "num_features = data_list[0].x.shape[1]\n",
        "epochs = 20\n",
        "edge_dim = data_list[0].edge_attr.shape[1]\n",
        "heads = 1\n",
        "hidden_channels = 1\n",
        "print(f'Node features: {num_features}')\n",
        "print(f'Edge features: {edge_dim}')\n",
        "split = [0.8, 0.2]\n",
        "N_train = int(N * split[0])\n",
        "train_data = data_list[:N_train]\n",
        "test_data = data_list[N_train:]\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "model_config = {\n",
        "    \"in_channels\": num_features,\n",
        "    \"hidden_channels\": hidden_channels,\n",
        "    \"out_channels\": out_channels,\n",
        "    \"num_layers\": num_layers,\n",
        "    \"edge_dim\": edge_dim,\n",
        "    \"heads\": heads\n",
        "    }\n",
        "# model\n",
        "model = DimeNet_OG(\n",
        "            hidden_channels=64,\n",
        "            out_channels=hidden_channels,\n",
        "            num_blocks=4,\n",
        "            num_bilinear=8,\n",
        "            num_spherical=7,\n",
        "            num_radial=6,\n",
        "            cutoff=5.0,\n",
        "            envelope_exponent=5,\n",
        "            num_before_skip=1,\n",
        "            num_after_skip=2,\n",
        "            num_output_layers=3,\n",
        "        ).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hie77fi7yGPc",
        "outputId": "333d59fa-cb61-45ab-dc7d-a99c8be1f312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features: 11\n",
            "Edge features: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "XtuDcPtEzMXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('before training')\n",
        "z = []\n",
        "for g in train_loader:\n",
        "    g = g.to(device)\n",
        "    z.append(model_og(g.z, g.pos, g.batch).detach().cpu().numpy())\n",
        "z = np.vstack(z)\n",
        "print(z.shape)\n",
        "cnt = 0\n",
        "for idx in range(z.shape[0]):\n",
        "    if np.any(z[idx] != 0): cnt+=1\n",
        "print(f'number of non-zero embeddings: {cnt}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_9ZhBp2yt3U",
        "outputId": "fe15979e-8f6a-4296-bc68-c4323bf4f564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training\n",
            "tensor([[  1,   2,   3,  ..., 226, 227, 228],\n",
            "        [  0,   0,   0,  ..., 229, 229, 229]], device='cuda:0')\n",
            "tensor([[  1,   2,   3,  ..., 327, 329, 330],\n",
            "        [  0,   0,   0,  ..., 331, 331, 331]], device='cuda:0')\n",
            "tensor([[  1,   2,   3,  ..., 189, 190, 191],\n",
            "        [  0,   0,   0,  ..., 192, 192, 192]], device='cuda:0')\n",
            "(755, 1)\n",
            "number of non-zero embeddings: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "train_loss = []\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    # Loop over the training dataset\n",
        "    for graph in train_loader:\n",
        "        # Extract the data and labels\n",
        "        graph = graph.to(device)\n",
        "        x, pos, edge_index, y, batch = graph.z, graph.pos, graph.edge_index, graph.y[:, 0], graph.batch\n",
        "\n",
        "        # Reset the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(x, pos, batch)\n",
        "        loss = loss_fn(output, y)\n",
        "        train_loss.append(loss.item())\n",
        "        print(f'epoch: {epoch} loss: {loss.item()}')\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "xzaDZRf-yS5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss[20:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "SctQFTwqy9Rq",
        "outputId": "256ec3d1-aaf5-49ca-b556-55b51acd0390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f03ab7ac6a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('after training')\n",
        "z = []\n",
        "for g in train_loader:\n",
        "    g = g.to(device)\n",
        "    z.append(model(g.z, g.pos, g.batch).detach().cpu().numpy())\n",
        "z = np.vstack(z)\n",
        "print(z.shape)\n",
        "cnt = 0\n",
        "for idx in range(z.shape[0]):\n",
        "    if np.any(z[idx] != 0): cnt+=1\n",
        "print(f'number of non-zero embeddings: {cnt}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E79Cn0YdyoZE",
        "outputId": "ab8729da-7dc8-4e69-d084-d830480c19f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after training\n",
            "(80, 1)\n",
            "number of non-zero embeddings: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = data_list[0].to(device)\n",
        "model(g.z, g.pos, batch=None, debug=True)"
      ],
      "metadata": {
        "id": "rOEU1t8QwRX9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}